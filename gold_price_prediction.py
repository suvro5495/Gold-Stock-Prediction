# -*- coding: utf-8 -*-
"""Gold-Price-Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/115TEPyL8WJ4-ts1ozeHizYZdSa-gOZGV

# Problem statement:
This project aims to leverage a comprehensive dataset of daily gold prices spanning from January 19, 2014, to January 22, 2024, obtained from Nasdaq. The dataset encompasses key financial metrics for each trading day, including the opening and closing prices, trading volume, as well as the highest and lowest prices recorded during the day.

Reading gold stock data (avaliable at: https://www.kaggle.com/datasets/sahilwagh/gold-stock-prices)

##Principle Aim:
The main goal of the project is to analyze daily gold prices over a ten-year period, using key financial metrics such as opening and closing prices, trading volume, and highest and lowest prices. This analysis aims to identify trends, patterns, and factors influencing gold prices, and develop predictive models for forecasting future gold prices.
"""

# Data Loading
from google.colab import drive
import pandas as pd
drive.mount('/content/drive')
file_path = '/content/drive/My Drive/goldstock.csv'
df = pd.read_csv(file_path)

df.head()

df.tail()

df.info()

"""##Features:

i. Date- A unique identifier for each trading day.

ii. Close- Closing price of gold on the respective date.

iii. Volume- Gold trading volume on the corresponding date.

iv. Open- Opening price of gold on the respective date.

v. High- The highest recorded price of gold during the trading day.

vi. Low- The lowest price recorded for gold in the trading day.


##Target Variable:

** Close- Closing price of gold on the respective date.
"""

df.shape

df.isnull().sum()

df.duplicated().sum()

df.describe()

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.filterwarnings('ignore')
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics

df = df.drop("Unnamed: 0", axis = 1)
df

correlation = df.corr()
plt.figure(figsize = (8,8))
sns.heatmap(correlation, cbar=True, square=True, fmt='.3f',annot=True, annot_kws={'size':15})

# Convert 'Date' column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Plot historical gold prices
plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Close'], label='Gold Price')
plt.xlabel('Year')
plt.ylabel('Gold Price')
plt.title('Historical Gold Prices')
plt.legend()
plt.show()

fig = plt.figure(figsize=(8, 8))
temp = df.drop("Date", axis=1).columns.tolist()
for i, item in enumerate(temp):
    plt.subplot(2, 3, i+1)
    sns.boxplot(data=df, x=item, color='violet')
plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=2.0)
plt.show()

df['Volume'].skew()

plt.figure(figsize = (16,5))
sns.distplot(df['Volume'])

df['Volume'].describe()

sns.boxplot(df['Volume'])

#finding the IQR # Calculate Q1 (25th percentile) and Q3 (75th percentile)

percentile25 = df['Volume'].quantile(0.25)
percentile75 = df['Volume'].quantile(0.75)

percentile75

IQR = percentile75 - percentile25
IQR

upperlimit = percentile75 + 1.5 *IQR
lowerlimit = percentile25 - 1.5 * IQR
print("Upperlimit : ", upperlimit)
print("lowerlimit : ", lowerlimit)

# Identify outliers
outliers = df[(df['Volume'] < lowerlimit) | (df['Volume'] > upperlimit)]

print("Outliers identified using IQR method:")
print('')
print(outliers)

df.drop(df[(df['Volume'] < lowerlimit) | (df['Volume'] > upperlimit)].index, inplace=True)

print("after removing outliers:", df.shape)

# Plot box plot for 'Volume' feature with logarithmic scaling
plt.figure(figsize=(6, 4))
plt.boxplot(df['Volume'])
plt.title('Distribution of Volume')
plt.ylabel('Value')
plt.xticks([1], ['Volume'])
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

# Select columns to normalize
columns_to_normalize = ['Volume', 'Open', 'High', 'Low', 'Close']

# Plot distributions before normalization
plt.figure(figsize=(17, 9))
for i, col in enumerate(columns_to_normalize):
    plt.subplot(2, len(columns_to_normalize), i+1)
    sns.histplot(df[col], kde=True, color='blue')
    plt.title(f'{col} before normalization')

# Fit the scaler on the selected columns and transform the data
df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])

# Plot distributions after normalization
for i, col in enumerate(columns_to_normalize):
    plt.subplot(2, len(columns_to_normalize), len(columns_to_normalize) + i + 1)
    sns.histplot(df[col], kde=True, color='orange')
    plt.title(f'{col} after normalization')

plt.tight_layout()
plt.show()

# Calculate correlation matrix
correlation  = df.corr()

# Create heatmap
sns.heatmap(correlation, cmap='coolwarm',
            center=0, annot=True)

# Set title and axis labels
plt.title('Correlation Matrix Heatmap')
plt.xlabel('Features')
plt.ylabel('Features')

# Show plot
plt.show()

"""Time Series Analysis:
Plot distribution of Gold Price and Trading Volume
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df is your DataFrame containing the time series data

# Plot distribution of Close prices and Volume
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.histplot(df['Close'], kde=True, color='#6495ED')
plt.title('Distribution of Close Prices')
plt.xlabel('Close Price')
plt.ylabel('Frequency')
plt.grid(True)

plt.subplot(1, 2, 2)
sns.histplot(df['Volume'], kde=True, color='green')
plt.title('Distribution of Volume')
plt.xlabel('Volume')
plt.ylabel('Frequency')
plt.grid(True)

plt.tight_layout()
plt.show()

df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Sort the DataFrame by the date index in ascending order
df = df.sort_index(ascending=True)

# Print the DataFrame to verify the changes
print(df.head())

#Extract features from Date column
df['Month'] = df.index.month
df['Year'] = df.index.year
df['Day'] = df.index.day
#df.drop('Date')

# Moving averages
window_1 = 50
window_2 = 200
close_prices_ma_1 = df['Close'].rolling(window=window_1).mean()
close_prices_ma_2 = df['Close'].rolling(window=window_2).mean()

plt.figure(figsize=(10, 6))
plt.plot(df.index, df['Close'], label="Close Price", color='#4040a1')
plt.plot(df.index, close_prices_ma_1, label="EMA 50 ", color='Salmon')
plt.plot(df.index, close_prices_ma_2, label="EMA 200 ", color='red')
plt.title('Close Price and Moving Averages')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
sns.barplot(x='Year', y='Close', data=df.groupby('Year')['Close'].mean().reset_index(), palette="husl")
plt.title('Average Gold Price by Year')
plt.xlabel('Year')
plt.ylabel('Average Gold Price (Close)')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

plt.figure(figsize=(10,4))
sns.barplot(x='Day', y='Close', data=df.groupby('Day')['Close'].mean().reset_index(), color='#9370DB')
plt.title('Average Gold Price by Day')
plt.xlabel('Day')
plt.ylabel('Average Gold Price (Close)')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

custom_palette = sns.color_palette("husl", 12)

fig, ax = plt.subplots(figsize=(20,8))
sns.boxplot(x=df.index.month_name(), y=df['Close'], ax=ax, palette=custom_palette)
plt.title('Gold Price by Month from 2012 to 2024')
plt.xlabel('Month')
plt.ylabel('Price')
plt.show()

plt.figure(figsize=(20,10))
plt.title('Seasonality of the Time Series')

sns.barplot(x='Month', y='Close', data=df , hue='Year')

plt.xlabel('Month')
plt.ylabel('Close Price')

plt.grid(True)
plt.show()

# Calculate daily returns
daily_returns = df['Close'].pct_change()

# Plot the daily returns
plt.plot(daily_returns.index, daily_returns,color='blue')
plt.xlabel("Date")
plt.ylabel("Daily Return (%)")
plt.title("Daily Returns of Gold Prices")
plt.tight_layout()
plt.show()

from statsmodels.tsa.seasonal import seasonal_decompose

result = seasonal_decompose(df['Close'], model='additive', period=365)
fig, axes = plt.subplots(4, 1, figsize=(10, 8))

# Plot each component and set the color to blue
result.observed.plot(ax=axes[0], color='blue')
axes[0].set_ylabel('Observed')

result.trend.plot(ax=axes[1], color='blue')
axes[1].set_ylabel('Trend')

result.seasonal.plot(ax=axes[2], color='blue')
axes[2].set_ylabel('Seasonal')

result.resid.plot(ax=axes[3], color='blue')
axes[3].set_ylabel('Residual')

plt.tight_layout()
plt.show()

import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.linear_model import LinearRegression
from keras.models import Sequential
from keras.layers import LSTM, Dense
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from math import sqrt
from sklearn.metrics import r2_score
from tensorflow.keras import regularizers

df.head(2)

"""##Splitting data to train and test"""

# Split the data into features (X) and target variable (y)
X = df[['Volume', 'Open', 'High', 'Low']]  # Features: Volume, Open, High, Low
y = df['Close']  # Target variable: Closing price

split_index = pd.to_datetime('2022-01-01')

train = df[df.index <= split_index]
test = df[df.index > split_index]

X_train = train.drop(columns=['Close'])
y_train = train['Close']

X_test = test.drop(columns=['Close'])
y_test = test['Close']

print(" X_train:", X_train.shape)
print(" y_train:", y_train.shape)
print(" X_test:", X_test.shape)
print(" y_test:", y_test.shape)
train_pct = len(train) / len(df) * 100
test_pct = len(test) / len(df) * 100
print()
print("Percentage of data in training set:", round(train_pct, 2), '%')
print("Percentage of data in testing set:", round(test_pct, 2), '%')

train['Close'].plot(figsize=(15,5), color='blue')
test['Close'].plot(figsize=(15,5), fontsize=15,color='OrangeRed')
plt.grid()
plt.legend(['Train Data', 'Test Data'])
plt.title('Train and Test Data')
plt.xlabel('Year')
plt.ylabel('Gold Price')
plt.show()

param_grid = {
    'fit_intercept': [True, False],
    'positive': [True, False]
}

linear_reg = LinearRegression()
grid_search = GridSearchCV(estimator=linear_reg, param_grid=param_grid, cv=10, scoring='r2', verbose=1)

grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
best_linear_reg = grid_search.best_estimator_

y_pred = best_linear_reg.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print evaluation metrics
print("Evaluation Metrics:")
print()
print("Best Hyperparameters:", best_params)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)
print("R-squared (R2):", r2)

test_scores = grid_search.cv_results_['split0_test_score'], grid_search.cv_results_['split1_test_score'], grid_search.cv_results_['split2_test_score'], grid_search.cv_results_['split3_test_score'], grid_search.cv_results_['split4_test_score'], grid_search.cv_results_['split5_test_score'], grid_search.cv_results_['split6_test_score'], grid_search.cv_results_['split7_test_score'], grid_search.cv_results_['split8_test_score'], grid_search.cv_results_['split9_test_score']

# Print the cross-validation scores for all folds
print("Cross-validation scores for the Last Model:")
for i, scores in enumerate(zip(*test_scores)):
    print(f"CV {i + 1}: {scores}")

plt.figure(figsize=(10, 5))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], lw=4, color='Magenta')
plt.title('Actual vs. Predicted Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.grid(True)
plt.show()

residuals = y_test - y_pred
plt.figure(figsize=(6, 4))
plt.scatter(y_pred, residuals, color='blue')
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.title('Residuals Plot')
plt.xlabel('Predicted Prices')
plt.ylabel('Residuals')
plt.grid(True)
plt.show()

"""##LSTM model for predictive analytics"""

def create_sequences(df, column_name, sequence_length):
    sequence_as_np = df[column_name].to_numpy()
    X = []
    y = []

    for i in range(len(sequence_as_np) - sequence_length):
        row = [[a] for a in sequence_as_np[i:i + sequence_length]]
        X.append(row)
        label = sequence_as_np[i + sequence_length]
        y.append(label)

    return np.array(X), np.array(y)

SEQUENCE_LENGTH = 30
X, y = create_sequences(df, 'Close', SEQUENCE_LENGTH)
X = X.reshape(X.shape[0], -1)

# Normalize data
scaler = MinMaxScaler(feature_range=(0, 1))
X = scaler.fit_transform(X)
y = scaler.fit_transform(y.reshape(-1, 1))
input = 2250
X_train, y_train = X[:input], y[:input]
X_test, y_test = X[input:], y[input:]
X_train.shape, y_train.shape , X_test.shape, y_test.shape
X_train = X_train.reshape(X_train.shape[0], SEQUENCE_LENGTH, 1)
X_test = X_test.reshape(X_test.shape[0], SEQUENCE_LENGTH, 1)
model = Sequential()
model.add(LSTM(units=100, activation='relu', return_sequences=False, input_shape=(SEQUENCE_LENGTH, 1)))
model.add(Dense(units=1))

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mean_squared_error')

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping])
y_predlstm = model.predict(X_test)

y_predlstm = y_predlstm.reshape(-1, 1)

y_predlstm  = scaler.inverse_transform(y_predlstm )
y_test = scaler.inverse_transform(y_test)

mse = mean_squared_error(y_test, y_predlstm)
rmse = sqrt(mse)
r_squared = r2_score(y_test, y_predlstm)

print(f'Mean Squared Error on Test Set: {mse}')
print(f'Root Mean Squared Error on Test Set: {rmse}')
print(f'R-squared on Test Set: {r_squared}')

plt.plot(y_test, label='Actual',color='blue')
plt.plot(y_predlstm, label='Predicted',color='DeepPink')
plt.title('Actual vs Predicted close')
plt.xlabel('Time Steps')
plt.ylabel('Close')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Training Loss',color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss',color='DeepPink')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

sns.regplot(x=y_test.flatten(), y=y_predlstm.flatten(), scatter_kws={'color': 'blue'}, line_kws={'color': 'hotpink'})
plt.title('Actual vs. Predicted Prices with Regression Line')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.show()

lookback_period = 50
entry_threshold = 2.0
exit_threshold = 0.0

df['RollingMean'] = df['Close'].rolling(window=lookback_period).mean()
df['RollingStd'] = df['Close'].rolling(window=lookback_period).std()

# Calculate upper and lower bands for entry and exit
df['UpperBand'] = df['RollingMean'] + entry_threshold * df['RollingStd']
df['LowerBand'] = df['RollingMean'] - entry_threshold * df['RollingStd']
exit_band = df['RollingMean'] + exit_threshold * df['RollingStd']

# Initialize trading signals
df['Signal'] = 0

# Generate trading signals
for i in range(lookback_period, len(df)):
    if df['Close'].iloc[i] > df['UpperBand'].iloc[i]:
        df.at[df.index[i], 'Signal'] = -1  # Sell signal (price above upper band)
    elif df['Close'].iloc[i] < df['LowerBand'].iloc[i]:
        df.at[df.index[i], 'Signal'] = 1  # Buy signal (price below lower band)
    elif df['Close'].iloc[i] > exit_band.iloc[i]:
        df.at[df.index[i], 'Signal'] = 0  # Exit signal (price above exit band)
    elif df['Close'].iloc[i] < exit_band.iloc[i]:
        df.at[df.index[i], 'Signal'] = 0  # Exit signal (price below exit band)

# Backtesting
initial_capital = 100000  # Initial capital in dollars
position = 0  # Initial position
cash = initial_capital  # Initial cash
portfolio_value = []  # Portfolio value over time

for i in range(lookback_period, len(df)):
    if df['Signal'].iloc[i] == 1:
        # Enter long position
        position = cash / df['Close'].iloc[i]  # Invest all available cash
        cash = 0  # No remaining cash after buying
    elif df['Signal'].iloc[i] == -1:
        # Enter short position
        cash += position * df['Close'].iloc[i]  # Sell all owned assets
        position = 0  # No remaining position after selling
    elif df['Signal'].iloc[i] == 0:
        # Exit position
        cash += position * df['Close'].iloc[i]  # Sell all owned assets
        position = 0  # No remaining position after selling

    # Calculate portfolio value
    portfolio_value.append(cash + position * df['Close'].iloc[i])

# Calculate performance metrics
total_return = (portfolio_value[-1] - initial_capital) / initial_capital
daily_returns = np.diff(portfolio_value) / portfolio_value[:-1]
sharpe_ratio = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252)  # Assuming 252 trading days in a year
max_drawdown = np.max(np.maximum.accumulate(portfolio_value) - portfolio_value) / initial_capital

# Plotting
# Plotting
plt.figure(figsize=(17, 10))
plt.plot(df.index, df['Close'], label='Close Price', color='blue')
plt.plot(df.index, df['RollingMean'], label='Rolling Mean', color='orange')
plt.plot(df.index, df['UpperBand'], label='Upper Band', color='red', linestyle='--')
plt.plot(df.index, df['LowerBand'], label='Lower Band', color='green', linestyle='--')

# Filter 'Close' prices for buy and sell signals
buy_indices = df[df['Signal'] == 1].index
sell_indices = df[df['Signal'] == -1].index
buy_prices = df.loc[df['Signal'] == 1, 'Close']
sell_prices = df.loc[df['Signal'] == -1, 'Close']

# Plot buy and sell signals
plt.scatter(buy_indices, buy_prices, label='Buy Signal', marker='^', color='green')
plt.scatter(sell_indices, sell_prices, label='Sell Signal', marker='v', color='red')

plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Reverse Trading Strategy')
plt.legend()
plt.grid(True)
plt.show()

# Count the number of buy and sell signals
total_trades = len(df[df['Signal'] != 0])

# Count the number of successful buy and sell signals
successful_buy_trades = len(df[(df['Signal'] == 1) & (df['Close'] < df['UpperBand'])])
successful_sell_trades = len(df[(df['Signal'] == -1) & (df['Close'] > df['LowerBand'])])

# Calculate win rates
buy_win_rate = successful_buy_trades / total_trades
sell_win_rate = successful_sell_trades / total_trades

# Print win rates
print("Buy Win Rate:", buy_win_rate)
print("Sell Win Rate:", sell_win_rate)